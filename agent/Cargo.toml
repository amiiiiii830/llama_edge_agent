[package]
name = "llama-agent"
version = "0.0.1"
edition = "2021"

[dependencies]
chat-prompts = "0.8.0"
endpoints = "0.8.0"
# llama-core = "0.11.1"
# chat-prompts = { path = "../api-server/chat-prompts" }
# endpoints = { path = "../api-server/endpoints" }
llama-core = { path = "../llama-core" }
wasmedge-wasi-nn = "0.7.0"
clap = { version = "4.4.6", features = ["cargo"] }
once_cell = "1.18"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "1"
anyhow = "1.0"
tokio_wasi = { version = "1", features = ["full"] }
futures = { version = "0.3.6", default-features = false, features = ["async-await", "std"] }
lazy_static = "1.4.0"
chrono = "0.4.38"
regex = "1.10.4"
reqwest = "0.11"
urlencoding = "2"
rustpython = { version = "0.3.1", default-features = false, features = ["encodings", "stdlib"] }
uuid = { version = "1.4", features = ["v4", "fast-rng", "macro-diagnostics"] }
